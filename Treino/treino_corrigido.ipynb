{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raafm\\Pessoal\\Ciencia-de-dados\\Stock-Prices-Prediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from treino_avaliacao import treinar_avaliar\n",
    "from Models.LSTM.LSTM import LSTMModel\n",
    "from Models.GRU.GRU import GRUModel\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_path = lambda  stock, get_labels,get_train: os.path.join(\"..\",\"FinalDatasets\", stock,f\"{stock}_{'y' if get_labels else 'X'}_timeseries_{'train' if get_train else 'test'}.npy\")\n",
    "\n",
    "X_train = np.load(get_dataset_path(stock= \"VALE3\", get_labels= False, get_train= True))\n",
    "y_train = np.load(get_dataset_path(stock= \"VALE3\", get_labels= True, get_train= True))\n",
    "X_test  = np.load(get_dataset_path(stock= \"VALE3\", get_labels= False, get_train= False))\n",
    "y_test  = np.load(get_dataset_path(stock= \"VALE3\", get_labels= True, get_train= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"..\\\\FinalDatasets\\\\VALE3\\\\VALE3_tabular_train.csv\")\n",
    "df_test = pd.read_csv(\"..\\\\FinalDatasets\\\\VALE3\\\\VALE3_tabular_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_target = df_train[\"hasRise\"]\n",
    "df_train.drop(columns= [\"Date\", \"hasRise\"], inplace= True)\n",
    "df_test.drop(columns= [\"Date\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,\n",
       " [(('bom negócio_count', 'valorização_count'), 1.0),\n",
       "  (('lucro_count', 'valorização_count'), 1.0),\n",
       "  (('lucro_count', 'bom negócio_count'), 1.0),\n",
       "  (('neutro_count', 'valorização_count'), 1.0),\n",
       "  (('neutro_count', 'bom negócio_count'), 1.0),\n",
       "  (('neutro_count', 'lucro_count'), 1.0),\n",
       "  (('desvalorização_count', 'valorização_count'), 1.0),\n",
       "  (('desvalorização_count', 'bom negócio_count'), 1.0),\n",
       "  (('desvalorização_count', 'lucro_count'), 1.0),\n",
       "  (('desvalorização_count', 'neutro_count'), 1.0)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_highly_correlated_features(correlation_matrix, threshold):\n",
    "  correlated_pairs = []\n",
    "  for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "      if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "        pair = (correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "        coefficient = correlation_matrix.iloc[i, j]\n",
    "        correlated_pairs.append((pair, coefficient))\n",
    "  return sorted(correlated_pairs, key= lambda pair: pair[1], reverse=True)\n",
    "\n",
    "MAX_CORRELATION = 0.90\n",
    "\n",
    "corr_matrix = df_train.corr(method='spearman').abs()\n",
    "correlation_list = get_highly_correlated_features(corr_matrix, MAX_CORRELATION)\n",
    "len(correlation_list), correlation_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop high correlated features in correlation list\n",
    "\n",
    "f2drop = []\n",
    "for feature_pair, _ in correlation_list:\n",
    "  if feature_pair[0] not in f2drop and feature_pair[1] not in f2drop:\n",
    "    f2drop.append(feature_pair[1])\n",
    "\n",
    "df_train_reduced = df_train.drop(f2drop, axis='columns')\n",
    "df_test_reduced = df_test.drop(f2drop, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_reduced.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_train_sets import get_sequences_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_reduced[\"hasRise\"] = coluna_target \n",
    "X_train_reduced, y_train_reduced = get_sequences_X_y(df_train_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced, y_test_reduced = get_sequences_X_y(df_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370, 7, 40), (115, 7, 40))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape,X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colocar dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.LSTM.LSTM_dropout import LSTMModel_dropout\n",
    "from Models.GRU.GRU_dropout import GRUModel_dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treino_avaliacao import treinar, avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 20\n",
    "file_to_save_model = \"low_corr_features.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-11 23:03:18,438] A new study created in memory with name: no-name-efac26d5-cc3e-48aa-806b-ac0656403176\n"
     ]
    }
   ],
   "source": [
    "model = treinar( X_train_reduced, y_train_reduced,LSTMModel_dropout, n_trials, 'VALE3'+file_to_save_model)\n",
    "avaliar(model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treinar( X_train_reduced, y_train_reduced,GRUModel_dropout, n_trials, 'VALE3'+file_to_save_model)\n",
    "avaliar(model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"..\\\\FinalDatasets\\\\PETR4\\\\PETR4_tabular_train.csv\")\n",
    "df_test = pd.read_csv(\"..\\\\FinalDatasets\\\\PETR4\\\\PETR4_tabular_test.csv\")\n",
    "\n",
    "coluna_target = df_train[\"hasRise\"]\n",
    "df_train.drop(columns= [\"Date\", \"hasRise\"], inplace= True)\n",
    "df_test.drop(columns= [\"Date\"], inplace= True)\n",
    "\n",
    "# Drop high correlated features in correlation list\n",
    "\n",
    "f2drop = []\n",
    "for feature_pair, _ in correlation_list:\n",
    "  if feature_pair[0] not in f2drop and feature_pair[1] not in f2drop:\n",
    "    f2drop.append(feature_pair[1])\n",
    "\n",
    "df_train_reduced = df_train.drop(f2drop, axis='columns')\n",
    "df_test_reduced = df_test.drop(f2drop, axis='columns')\n",
    "\n",
    "df_train_reduced[\"hasRise\"] = coluna_target \n",
    "X_train_reduced, y_train_reduced = get_sequences_X_y(df_train_reduced)\n",
    "X_test_reduced, y_test_reduced = get_sequences_X_y(df_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370, 7, 40), (115, 7, 40))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape,X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treinar( X_train_reduced, y_train_reduced,LSTMModel_dropout, n_trials, 'PETR4'+file_to_save_model)\n",
    "avaliar(model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treinar( X_train_reduced, y_train_reduced,GRUModel_dropout, n_trials, 'PETR4'+file_to_save_model)\n",
    "avaliar(model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
